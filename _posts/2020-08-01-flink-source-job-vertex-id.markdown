---
title: "æµ…è°ˆ Flink - JobGraph ä¹‹ JobVertexID"
date: 2020-08-01 00:56:34
tags: [flink-1.9]
---

[ä¸Šä¸€ç¯‡ç¬”è®°](https://izualzhy.cn/flink-source-kafka-checkpoint-read)çœ‹åˆ° restore state æ—¶æ‰¾ä¸åˆ° operator id çš„é—®é¢˜ï¼š

```
Cannot map checkpoint/savepoint state for operator 77fec41789154996bfa76055dea29472 to the new program
```

è¿™äº›æ•°å­—çš„å˜åŒ–ä¹çœ‹éå¸¸å¥‡æ€ªï¼Œè¿™ç¯‡ç¬”è®°å°è¯•åˆ†æä¸‹è¿™äº›æ•°å­—æ˜¯å¦‚ä½•ç”Ÿæˆçš„å¹¶ä¸”ä¿®å¤ä¸Šä¸ªä¾‹å­ã€‚

## 1. å”¯ä¸€OperatorID

OperatorID å¯¹åº”çš„å°±æ˜¯ StreamGraph é‡Œçš„èŠ‚ç‚¹ idï¼Œä¸è¿‡åœ¨ Transformation->StreamGraph é˜¶æ®µï¼Œéƒ½è¿˜æ˜¯è‡ªå¢çš„ idã€‚åœ¨ç”Ÿæˆ JobGraph æ—¶ï¼Œä¼šé¦–å…ˆä¸ºæ¯ä¸ª StreamNode ç”Ÿæˆ hashIDï¼Œä»£ç å…¥å£åœ¨[createJobGraph](https://izualzhy.cn/flink-source-job-graph#2-streamingjobgraphgenerator)ï¼Œé€šè¿‡`StreamGraphHasherV2.traverseStreamGraphAndGenerateHashes`å¾—åˆ°ã€‚

å®šä¹‰å”¯ä¸€ id æœ€ç®€å•æœ´ç´ é«˜æ•ˆçš„æ–¹å¼å¤§æ¦‚å°±æ˜¯ UUIDï¼Œä½†è€ƒè™‘æœ€åŸºç¡€çš„æƒ…å†µï¼Œå¦‚æœåªæ˜¯ç¨‹åºé‡å¯æˆ–è€…æŸä¸ª transform å†…éƒ¨ä¿®æ”¹ï¼Œid å¯ä»¥ä¿æŒä¸å˜ï¼Œä¹Ÿå°±æ˜¯å½“è¿™ä¸ª JobGraph æ²¡æœ‰å‘ç”Ÿæ”¹å˜æ—¶èŠ‚ç‚¹ id æ— é¡»æ”¹å˜ã€‚å½“èŠ‚ç‚¹åªæœ‰åç»­èŠ‚ç‚¹æ”¹å˜ï¼Œä¸”åç»­èŠ‚ç‚¹æ”¹å˜å¯¹è¯¥èŠ‚ç‚¹æ²¡æœ‰å½±å“æ—¶ï¼Œè¯¥èŠ‚ç‚¹çš„ id ä¹Ÿæ— é¡»å˜åŒ–ã€‚

å› æ­¤ï¼ŒèŠ‚ç‚¹çš„ id å–å†³äº 3 ä¸ªå› ç´ ï¼š  
1. èŠ‚ç‚¹åœ¨å›¾ä¸­çš„ä½ç½®ï¼Œç”¨äºåˆ¤æ–­å‰åºèŠ‚ç‚¹çš„éƒ¨åˆ†å›¾æ˜¯å¦å‘ç”Ÿäº†å˜åŒ–  
2. è¾“å…¥èŠ‚ç‚¹çš„idï¼Œåˆ¤æ–­è¾“å…¥èŠ‚ç‚¹æ˜¯å¦å‘ç”Ÿå˜åŒ–   
3. è¾“å‡ºèŠ‚ç‚¹(chainable)çš„ä¸ªæ•°  

å…¶å®ä¸åŒçš„ç”¨é€”ï¼Œid å–å†³çš„å› ç´ ä¹Ÿä¼šä¸åŒã€‚è¿™é‡Œä¹Ÿåªæ˜¯å¤§æ¦‚çš„çŒœæµ‹ï¼Œflink ä»é€šç”¨æ€§çš„è§’åº¦ï¼Œå®ç°ä¸Šä¹Ÿä¼šæ›´ä¸¥æ ¼äº›ï¼Œæ„Ÿå…´è¶£çš„å¯ä»¥ç›´æ¥çœ‹ä¸‹`traverseStreamGraphAndGenerateHashes`è¿™å—ä»£ç ã€‚

ä¸ºäº†æé«˜æ˜“ç”¨æ€§ï¼Œflink è¿˜æä¾›äº†æ‰‹åŠ¨è®¾ç½®[Assigning Operator IDs](https://ci.apache.org/projects/flink/flink-docs-master/ops/state/savepoints.html#assigning-operator-ids)çš„æ–¹å¼ï¼Œ`uid`æ¥å£ç”¨äºç”ŸæˆèŠ‚ç‚¹ id.

## 2. traverseStreamGraphAndGenerateHashes

æˆ‘ä»¬æ¨¡ä»¿`traverseStreamGraphAndGenerateHashes`å®ç°ä¸€ä¸ªç®€å•çš„ç‰ˆæœ¬ï¼š

`MicroStreamGraph`è®°å½•äº†å½±å“ hash å€¼çš„å‡ ä¸ªå…ƒç´ ï¼Œå¦‚æœæ²¡æœ‰è®¾ç½®`uid`ï¼Œé€šè¿‡(è¾“å…¥èŠ‚ç‚¹id, chainableçš„å‡ºè¾¹ä¸ªæ•°ï¼ŒèŠ‚ç‚¹ä½ç½®)è®¡ç®—ï¼Œå¦‚æœè®¾ç½®äº†`uid`ï¼Œåˆ™åŸºäºè®¾ç½®å€¼è®¡ç®—ã€‚

å…¶ä¸­æ„é€ äº†ä¸¤ä¸ª`StreamNodes`ï¼Œå¯¹åº”å‰é¢çš„ä¸¤ä¸ªä¾‹å­ï¼š[StreamWithStateSample](https://izualzhy.cn/flink-source-kafka-checkpoint-init#3-reading-state)ã€[Word Count](https://izualzhy.cn/flink-source-transformations#1-%E5%BC%80%E7%AF%87)

```scala
object JobVertexGenerator extends App {
  val hashFunction = Hashing.murmur3_128(0)
  val hashes = mutable.HashMap.empty[Int, Array[Byte]]

  // Plan
  // {"nodes":[{"id":1,"type":"Source: Custom Source","pact":"Data Source","contents":"Source: Custom Source","parallelism":4},{"id":2,"type":"Map","pact":"Operator","contents":"Map","parallelism":4,"predecessors":[{"id":1,"ship_strategy":"FORWARD","side":"second"}]},{"id":4,"type":"Map","pact":"Operator","contents":"Map","parallelism":4,"predecessors":[{"id":2,"ship_strategy":"HASH","side":"second"}]},{"id":5,"type":"Sink: Print to Std. Out","pact":"Data Sink","contents":"Sink: Print to Std. Out","parallelism":4,"predecessors":[{"id":4,"ship_strategy":"FORWARD","side":"second"}]}]}

  case class MicroStreamGraph(nodeId: Int,
                              userSpecifiedUID: String,
                              chainableOutEdgeCnt: Int,
                              inEdgeNodeIds: List[Int])

  // https://izualzhy.cn/flink-source-kafka-checkpoint-init#3-reading-state
  val streamNodes = List(
    MicroStreamGraph(1, "source_uid", 1, List.empty[Int]),
    MicroStreamGraph(2, null, 0, List(1)),
    MicroStreamGraph(4, "count_uid", 1, List(2)),
    MicroStreamGraph(5, null, 0, List(4))
  )
  /*
  // https://izualzhy.cn/flink-source-job-graph
  val streamNodes = List(
    MicroStreamGraph(1, null, 1, List.empty[Int]),
    MicroStreamGraph(2, null, 0, List(1)),
    MicroStreamGraph(4, null, 0, List(2)),
    MicroStreamGraph(5, null, 0, List(4))
  )
   */

  // StreamGraphHasherV2.traverseStreamGraphAndGenerateHashes
  streamNodes.map{
    case streamNode if streamNode.userSpecifiedUID == null =>
      // StreamGraphHasherV2.generateDeterministicHash
      val hasher = hashFunction.newHasher()

      hasher.putInt(hashes.size)
      (0 until streamNode.chainableOutEdgeCnt).foreach(_ => hasher.putInt(hashes.size))

      val hash = hasher.hash().asBytes()

      streamNode.inEdgeNodeIds.foreach{inEdgeNodeId =>
        val inEdgeNodeHash = hashes(inEdgeNodeId)

        println(s"inEdgeNodeHash:${byteToHexString(inEdgeNodeHash)}")
        (0 until hash.length).foreach(i =>
          hash(i) = (hash(i) * 37 ^ inEdgeNodeHash(i)).toByte)
      }
      println(s"hash:${byteToHexString(hash)}")
      hashes.update(streamNode.nodeId, hash)

    case streamNode if streamNode.userSpecifiedUID != null =>
      // StreamGraphHasherV2.generateUserSpecifiedHash
      // OperatorIDGenerator.fromUid
      val hasher = hashFunction.newHasher()
      hasher.putString(streamNode.userSpecifiedUID.toString, Charset.forName("UTF-8"))
      hashes.update(streamNode.nodeId, hasher.hash().asBytes())
  }

  streamNodes.foreach(streamNode => println(s"${streamNode.nodeId} ${byteToHexString(hashes(streamNode.nodeId))}"))
}
```

å¯¹äºç¬¬ä¸€ä¸ª StreamNodesï¼Œè¾“å‡ºç»“æœä¸º

```
1 64248066b88fd35e9203cd469ffb4a53
2 d216482dd1005af6d275607ff9eabe2c
4 77fec41789154996bfa76055dea29472
5 f0bb9ed0d20321fef7413e1942e21550
```

å¯ä»¥çœ‹åˆ°è¿™é‡Œè·Ÿ[è¯»å– Stateæ—¶](https://izualzhy.cn/flink-source-kafka-checkpoint-read#4-stateviewer-%E6%89%AB%E6%8F%8F-managedoperatorstate)å¾—åˆ°çš„ operatorID æ˜¯ä¸€è‡´çš„ã€‚
ä¹Ÿå¯ä»¥ç¡®è®¤`operatorID:77fec41789154996bfa76055dea29472`çš„ state size = 2114ï¼Œå¯¹åº”çš„å°±æ˜¯`map(new CountFunction)`ã€‚

å¯¹äºç¬¬äºŒä¸ª StreamNodesï¼Œè¾“å‡ºç»“æœä¸º

```
1 cbc357ccb763df2852fee8c4fc7d55f2
2 7df19f87deec5680128845fd9a6ca18d
4 9dd63673dd41ea021b896d5203f3ba7c
5 1a936cb48657826a536f331e9fb33b5e
```

è·Ÿ[è¿™é‡Œçš„æ—¥å¿—](https://izualzhy.cn/flink-source-job-graph#5-%E7%A4%BA%E4%BE%8B)ä¸€è‡´ã€‚  
*æ³¨ï¼šæœ cbc357ccb763df2852fee8c4fc7d55f2ï¼Œå¤§éƒ¨åˆ†éƒ½æ˜¯å…³äº flink çš„ç»“æœğŸ˜…*

äº‹å®ä¸Šï¼Œå¯åŠ¨`StreamWithStateSample`çš„æ—¥å¿—é‡Œä¹Ÿè®°å½•äº†é`uid`çš„hashå€¼(å¯¹äº`uid`çš„ hash å€¼ï¼Œflinké»˜è®¤ä¸ä¼šè®°å½•åˆ°æ—¥å¿—)

```
... DEBUG org.apache.flink.streaming.api.graph.StreamGraphHasherV2Â  Â  Â  - Generated hash 'd216482dd1005af6d275607ff9eabe2c' for node 'Map-2' {id: 2, parallelism: 1, user function: org.apache.flink.streaming.api.scala.DataStream$$anon$4}
... DEBUG org.apache.flink.streaming.api.graph.StreamGraphHasherV2Â  Â  Â  - Generated hash 'f0bb9ed0d20321fef7413e1942e21550' for node 'Sink: Print to Std. Out-5' {id: 5, parallelism: 1, user function: org.apache.flink.streaming.api.functions.sink.PrintSinkFunction}
```

åˆ°äº†è¿™é‡Œï¼Œå…³äº[OperatorIDæŠ¥é”™](https://izualzhy.cn/flink-source-kafka-checkpoint-read#1-mock-flinkkafkaconsumerbase)çš„ä¿®å¤ä¹Ÿå°±æ¯”è¾ƒç®€å•äº†ï¼Œå¢åŠ ç›¸åŒçš„`uid`å³å¯ã€‚

```scala
//  env.addSource(new MockKafkaSource).print()
env.addSource(new MockKafkaSource).uid("source_uid").print()
```

*æ³¨ï¼šå¯¹æ¯” flink æºç é‡Œçš„ java å®ç°ï¼Œscala çš„è¿™ä¸ªä¾‹å­è™½ç„¶ä»£ç è¡Œæ•°æ›´å°‘ï¼Œä½†æ˜¯å¯è¯»æ€§å¹¶ä¸é«˜ã€‚æºç é‡Œçš„è¿™æ®µé€»è¾‘å¹¶ä¸ç®€å•ï¼Œç›¸æ¯”ä¹‹å‰ State çš„ä»£ç å®ç°è¦ä¼˜é›…å¾ˆå¤š*

## 3. OperatorID åº”ç”¨
### 3.1. State

flink æ”¯æŒæœ‰çŠ¶æ€çš„è®¡ç®—ï¼ŒçŠ¶æ€æ˜¯è·Ÿæ¯ä¸€ä¸ª JobVertexID å…³è”çš„ï¼Œé€šè¿‡`SavePoint.getOperatorStates`æ¥å£å£°æ˜ä¹Ÿå¯ä»¥è¯´æ˜è¿™ç‚¹ã€‚ä» state æ¢å¤æ—¶ä¹Ÿä¾èµ–é€ä¸ªéå†ä¸”æ˜ å°„æ¯ä¸ª OperatorID.

### 3.2. metrics

æ¯”å¦‚æˆ‘ä»¬é€šè¿‡[REST API](https://ci.apache.org/projects/flink/flink-docs-master/monitoring/metrics.html#rest-api-integration)æŸ¥çœ‹[ä¾‹å­](https://izualzhy.cn/flink-source-kafka-checkpoint-init#3-reading-state)é‡Œçš„ job çŠ¶æ€ï¼Œå¯ä»¥çœ‹åˆ°è¿™ä¹ˆä¸€ç»„ vertices:

```json
{
    ...
    "vertices":[
        {
            "id":"64248066b88fd35e9203cd469ffb4a53",
            "name":"Source: Custom Source -> Map",
            ...
        },
        {
            "id":"77fec41789154996bfa76055dea29472",
            "name":"Map -> Sink: Print to Std. Out",
            ...
        }
    ]
    ...
}
```

ä¹Ÿå°±æ˜¯å®é™…è¿è¡Œæ—¶èŠ‚ç‚¹ chain ä¼˜åŒ–ä¸ºäº†ä¸¤æ¡:

![StreamWithStateSample_running](/assets/images/flink-source-code/StreamWithStateSample_running.jpg)

metrics çœ‹åˆ°çš„èŠ‚ç‚¹éƒ½æ˜¯æ¯æ¡ chain çš„é¦–èŠ‚ç‚¹ï¼Œå¼€å¯äº†[Latency tracking](https://ci.apache.org/projects/flink/flink-docs-master/monitoring/metrics.html#latency-tracking)åï¼Œä¹Ÿå¯ä»¥çœ‹åˆ°æ¯ä¸ª OperatorID ä¹‹é—´çš„ latencyï¼Œå½¢å¦‚ã€Œlatency.source_id.X.source_subtask_index.0.operator_id.Y.operator_subtask_index.3.latency_p99ã€.

## 4. æ€»ç»“

StreamGraph ç”Ÿæˆ JobGraph çš„è¿‡ç¨‹ä¸­ï¼Œä¼šä¸ºæ¯ä¸ªèŠ‚ç‚¹ç”Ÿæˆ hash idï¼Œç”Ÿæˆè§„åˆ™ä¸ºï¼š  
1. å¦‚æœæŒ‡å®šäº† uidï¼Œåˆ™ä½¿ç”¨ uid hash ç»“æœï¼Œå¦‚æœç¡®è®¤ state å¯ä»¥å¤ç”¨ï¼Œå°±å¯ä»¥æ‰‹åŠ¨æŒ‡å®šã€‚  
2. å¦‚æœæ²¡æœ‰æŒ‡å®š uidï¼Œåˆ™è·Ÿè¾“å…¥èŠ‚ç‚¹çš„ä¸ªæ•°ä»¥åŠè¾“å…¥èŠ‚ç‚¹æ˜¯å¦å‘ç”Ÿå˜åŒ–ï¼Œæ‰€åœ¨å›¾èŠ‚ç‚¹çš„ä½ç½®ï¼Œä»¥åŠå¯ chain çš„å‡ºè¾¹ä¸ªæ•°æœ‰å…³ã€‚

JobGraph chain æ—¶ï¼Œç¬¦åˆæ¡ä»¶çš„èŠ‚ç‚¹è¢« chain åˆ°é¦–èŠ‚ç‚¹ï¼Œç›¸å…³ç›‘æ§éƒ½ä½¿ç”¨é¦–èŠ‚ç‚¹ id.å½“ç„¶å…¨éƒ¨èŠ‚ç‚¹ id ä¹Ÿéƒ½è®°å½•ä¸‹æ¥ï¼Œç”¨äº latency è¿™ç±» metricsï¼Œstate å­˜å‚¨ç­‰ã€‚ä¾‹å¦‚åœ¨ latency metrci çš„å‘½åç»“æ„latency.source_id.X.source_subtask_index.0.operator_id.Y.operator_subtask_index.3.latency_p99ã€ï¼Œå…¶ä¸­ X Y éƒ½æ˜¯å¯¹åº”çš„ VertexIDï¼Œå¦‚æœèƒ½å¤Ÿä½¿ç”¨`uid` `name`ç­‰å¯è¯»æ€§æ˜æ˜¾æ›´é«˜ä¸€äº›ï¼Œæœ€å¼€å§‹æ¥è§¦ flink æ—¶åœ¨ç¤¾åŒºé‡Œä¹Ÿæè¿‡[ç–‘é—®](http://apache-flink.147419.n8.nabble.com/flink-Latency-tracking-td1800.html)ï¼Œä¸è¿‡æ²¡æœ‰å›åº”ï¼Œåæ¥çœ‹åˆ°[LatencyMetric scope should include operator names](https://issues.apache.org/jira/browse/FLINK-8592)ï¼Œflink çš„ owner æš‚æ—¶ä¸æ‰“ç®—å¢åŠ è¿™ä¸ªæ˜“ç”¨æ€§çš„åŠŸèƒ½ã€‚  

## 5. Ref

1. [Add operator name to latency metrics](https://issues.apache.org/jira/browse/FLINK-9653)  
2. [LatencyMetric scope should include operator names](https://issues.apache.org/jira/browse/FLINK-8592)  
3. [latency metrics é‡Œä½¿ç”¨ operator name](https://stackoverflow.com/questions/50994512/get-operator-name-in-flink-latency-metric)  