---
title: "è°ˆè°ˆ Flink - State ä¹‹ Kafka å†™å…¥ HBase"
date: 2020-08-16 10:28:51
tags: [flink-1.9]
---

å‰é¢ä»‹ç»äº†è¯»å– stateï¼Œè¿™ç¯‡ç¬”è®°ä»‹ç»ä¸‹ state æ˜¯å¦‚ä½•è§¦å‘å†™å…¥çš„ã€‚

## 1. Why

è€ƒè™‘è®¢é˜… Kafka å†™ HBase çš„åœºæ™¯ï¼š
1. å†™å…¥ HBase æ—¶ï¼Œä¸ºäº†è·å–æœ€å¤§çš„å†™å…¥æ€§èƒ½ï¼Œå¯èƒ½ä¼šå…ˆç¼“å­˜åˆ°å†…å­˜ç„¶åæ‰¹é‡å†™å…¥
2. æ¶ˆè´¹ Kafka æ—¶ï¼Œéœ€è¦è®°å½•å½“å‰çš„ offsetsï¼Œæ–¹ä¾¿é‡å¯æ—¶ç»§ç»­æ¶ˆè´¹ã€‚

å› æ­¤ï¼Œå°±éœ€è¦æœ‰æ•°æ®åŒæ­¥çš„æœºåˆ¶ï¼Œåœ¨ä¸Šä¼  kafka çš„ offsets å‰ï¼Œç¡®ä¿ hbase æ”¶åˆ°äº†å…¨éƒ¨æ•°æ®å¹¶ä¸”å°†å†…å­˜çš„æ•°æ®æŒä¹…åŒ–ï¼Œè¿™å°±æ˜¯ flink é‡Œ checkpoint çš„ä½œç”¨ã€‚

## 2. How

[Fault Tolerance via State Snapshots
](https://ci.apache.org/projects/flink/flink-docs-master/learn-flink/fault_tolerance.html)é‡Œè¿™å¼ å›¾ä»ç†è®ºä¸Šè§£é‡Šçš„éå¸¸æ¸…æ¥š:

![checkpoint barrier](https://ci.apache.org/projects/flink/flink-docs-master/fig/stream_barriers.svg)

ç®€å•æ¥è®²ï¼Œç›¸æ¯” spark ç‰©ç†ä¸Šå¾®æ‰¹å¤„ç†çš„æ–¹å¼ï¼Œflink åœ¨é€»è¾‘ä¸ŠåŒæ ·å°†æ•°æ®åˆ†æˆäº†æ‰¹æ¬¡ï¼Œæ•°æ®æ˜¯å®æ—¶é€æ¡å¤„ç†ï¼Œä½†æ˜¯åªæœ‰é€»è¾‘ä¸Šä¸€ä¸ªæ‰¹æ¬¡å¤„ç†å®Œäº†ï¼Œæ‰ä¼šå°† offsets æ›´æ–°åˆ° kafka.

[how-apache-flink-manages-kafka-consumer-offsets](https://www.ververica.com/blog/how-apache-flink-manages-kafka-consumer-offsets)è¿™é‡Œä¹Ÿæœ‰æ›´åŠ æ¸…æ™°çš„ä»‹ç»ã€‚

checkpoint éœ€è¦æ•°æ®æµä¸Šçš„ç®—å­æ•´ä½“å‚ä¸åè°ƒå®Œæˆï¼š

1. å½“æ”¶åˆ° checkpoint barrier æ—¶ï¼Œç®—å­å°†å½“å‰å†…å­˜çš„æ•°æ®æŒä¹…åŒ–  
2. å½“æ•°æ®æµä¸Šå…¨éƒ¨ç®—å­å®Œæˆ 1 é‡Œçš„åŠ¨ä½œåï¼Œå°±å¯ä»¥è®¤ä¸º barrier ä¹‹å‰çš„æ•°æ®å„ä¸ªç®—å­éƒ½å·²ç»æ‰¿è¯ºå¤„ç†å®Œæˆï¼Œæ­¤æ—¶ source ç®—å­å¯ä»¥å°† offsets ä¸Šä¼ åˆ° kafka 

è¿™ä¸¤ä¸ªæ­¥éª¤ï¼Œflink åˆ†åˆ«é€šè¿‡ä¸¤ä¸ªç±»æš´éœ²å‡ºå¯¹åº”çš„æ¥å£ï¼š

1. `CheckpointedFunction`: `initializeState`ç”¨äºåˆå§‹åŒ–ä»¥åŠæ¢å¤stateï¼Œ`snapshotState`å¯¹åº”å‘èµ· checkpoint æˆ–è€…æ”¶åˆ° barrier æ—¶çš„è¡Œä¸º
2. `CheckpointListener`: å„ä¸ªç®—å­çš„`snapshotState`éƒ½å·²å®Œæˆåï¼Œè°ƒç”¨`notifyCheckpointComplete(long checkpointId)`

æ³¨æ„ checkpoint å’Œ state å¹¶ä¸æ˜¯å¼ºç»‘å®šçš„å…³ç³»ï¼Œåœ¨ checkpoint æ—¶å¯ä»¥å®Œæˆ state åŒæ­¥åˆ°æ–‡ä»¶ç³»ç»Ÿï¼Œä¹Ÿå¯ä»¥æ˜¯å°†å†…å­˜çš„æ•°æ®æŒä¹…åŒ–åˆ°å­˜å‚¨ç³»ç»Ÿï¼Œç”±ç®—å­å†…éƒ¨å†³å®šã€‚å®Œæˆ`snapshotState`æ„å‘³ç€è¯¥ç®—å­æ‰¿è¯ºäº† checkpointId ä¹‹å‰çš„æ•°æ®å¤„ç†å®Œæˆã€‚å› æ­¤ï¼Œå¯ä»¥çŒœæµ‹åœ¨ flink-runtime é‡Œï¼Œéœ€è¦ä¿è¯åœ¨è°ƒç”¨ç®—å­çš„`snapshotState`ä¹‹å‰ï¼Œä¸€å®šå·²ç»å°†è¯¥ barrier ä¹‹å‰çš„å…¨éƒ¨æ•°æ®äº¤ç»™äº†ç®—å­å¤„ç†ã€‚è¿™ä¸ªé¡ºåºæ€§ï¼Œå¯¹æ‰€æœ‰çš„ç®—å­ä»¥åŠç®—å­æ‰€æœ‰ç‰©ç†å®ä¾‹éƒ½æ˜¯ä¸€è‡´çš„ã€‚é¡ºåºæ€§çš„ä¿è¯ï¼Œåº•å±‚æ˜¯å¤šçº¿ç¨‹+é”è¿˜æ˜¯å•çº¿ç¨‹æ¥å®ç°ï¼Œç”¨æˆ·åœ¨å®ç°ä¸€ä¸ªç®—å­æ—¶ä¹Ÿåº”å½“æ˜¯æ— æ„Ÿçš„ã€‚

å¤§éƒ¨åˆ†çš„æ–‡ç« éƒ½ä¼šå¼ºè°ƒ barrier å¦‚ä½•å¯¹é½ï¼Œè¿™çš„ç¡®æ˜¯ checkpoint ç†è®ºä¸­æœ€é‡è¦çš„ä¸€ç¯ã€‚ä¸è¿‡åœ¨ç¨å¾®äº†è§£äº† barrier çš„åŸç†åï¼Œæˆ‘ä»¬ä¹Ÿä¼šå¥½å¥‡ barrier æ˜¯ä»å“ªé‡Œæ¥çš„ï¼Œè¿™äº›ç†è®ºå’Œ flink æš´éœ²å‡ºæ¥çš„æ¥å£æ˜¯ä»€ä¹ˆå…³ç³»ï¼Œå¯¹äºè‡ªå®šä¹‰çš„ source/sinkï¼Œåº”è¯¥å¦‚ä½•å®ç°ç¡®ä¿æ•°æ®ä¸ä¸¢ï¼Ÿ

æ¥ä¸‹æ¥é€šè¿‡ä¸€ä¸ªä¾‹å­ï¼Œå°è¯•æŠŠè¿™äº›é—®é¢˜ä»‹ç»ä¸€ä¸ªåˆæ­¥çš„è½®å»“ï¼Œæ–¹ä¾¿æ„Ÿå…´è¶£çš„è¯»è€…ç»§ç»­æ·±å…¥ç†è§£ã€‚

## 3. ä¾‹å­ğŸŒ°

æˆ‘ä»¬é¦–å…ˆå®ç°ä¸¤ä¸ªç±»:`StateSource` `StateSink`ï¼Œè¿™ä¸¤ä¸ªç±»éƒ½é¢å¤–ç»§æ‰¿äº†`CheckpointedFunction` `CheckpointListener`

```scala
  def logPrint(className: String)(msg: String) = {
    println(s"${new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new Date())} L${Thread.currentThread().getId} ${className} ${msg}")
  }

  class StateSource extends SourceFunction[String] with CheckpointedFunction with CheckpointListener {
    private val log = logPrint(getClass.getSimpleName)_
    override def run(ctx: SourceFunction.SourceContext[String]): Unit = {
      (1 to 10000).foreach{i =>
        log(s"send:${i}")
        ctx.collect(i.toString)
        Thread.sleep(1000)
      }
    }

    override def cancel(): Unit = {}

    override def initializeState(context: FunctionInitializationContext): Unit = {
      log(s"initializeState")
    }
    override def snapshotState(context: FunctionSnapshotContext): Unit = {
      log(s"snapshotState begin")
//      log(s"snapshotState begin \n${Thread.currentThread().getStackTrace().mkString("\n")}")
      Thread.sleep(10000)
      log("snapshotState end")
    }

    override def notifyCheckpointComplete(checkpointId: Long): Unit = {
      log(s"notifyCheckpointComplete ${checkpointId}")
    }

  }

  class StateSink extends SinkFunction[String] with CheckpointedFunction with CheckpointListener {
    private val log = logPrint(getClass.getSimpleName)_
    override def invoke(value: String): Unit = {
      log(s"recv:${value}")
    }
    override def initializeState(context: FunctionInitializationContext): Unit = {
      log(s"initializeState")
    }
    override def snapshotState(context: FunctionSnapshotContext): Unit = {
      log(s"snapshotState begin")
//      log(s"snapshotState begin \n${Thread.currentThread().getStackTrace().mkString("\n")}")
      Thread.sleep(10000)
      log("snapshotState end")
    }
    override def notifyCheckpointComplete(checkpointId: Long): Unit = {
      log(s"notifyCheckpointComplete ${checkpointId}")
    }
  }
```

å¯ä»¥çœ‹åˆ°å®ç°éå¸¸ç®€å•ï¼Œsource ç«¯æ¯éš” 1s å‘é€ä¸€æ¡æ•°æ®ï¼Œsourceå‘é€ã€sinkæ¥æ”¶æ—¶éƒ½ä¼šæ‰“å°ä¸€æ¡æ—¥å¿—ï¼ŒåŒæ—¶ä¸¤è€…éƒ½å®ç°äº†`snapshotState`ï¼Œsleep 10s æ¨¡æ‹Ÿä¸€æ®µæŒä¹…åŒ–çš„æ“ä½œã€‚

```scala
  val env = StreamExecutionEnvironment.getExecutionEnvironment
  val fsStateBackend = new FsStateBackend("file:///tmp")
  env.setStateBackend(fsStateBackend)
  env.enableCheckpointing(60000)

  env.addSource(new StateSource)
    .addSink(new StateSink)
    .setParallelism(1)

  env.execute(s"${getClass}")
```

ä¸ºäº†èšç„¦é—®é¢˜ï¼Œè¿è¡Œä¹Ÿéå¸¸ç®€å•ï¼ŒSource -> Sinkï¼Œä¸­é—´æ²¡æœ‰æ•°æ®å¤„ç†ï¼›ä¸ºäº†ç¡®ä¿ source/sink chain ä¸ºä¸€ä¸ªèŠ‚ç‚¹ï¼Œæˆ‘ä»¬è®¾ç½® sink çš„å¹¶å‘ä¸º1ã€‚

è§‚å¯Ÿä¸‹è¾“å‡ºï¼š

```
2020-08-16 21:38:02 L53 StateSink initializeState
2020-08-16 21:38:02 L53 StateSource initializeState
2020-08-16 21:38:02 L55 StateSource send:1
2020-08-16 21:38:02 L55 StateSink recv:1
2020-08-16 21:38:03 L55 StateSource send:2
2020-08-16 21:38:03 L55 StateSink recv:2
2020-08-16 21:38:04 L55 StateSource send:3
2020-08-16 21:38:04 L55 StateSink recv:3
...
2020-08-16 21:38:55 L55 StateSource send:54
2020-08-16 21:38:55 L55 StateSink recv:54
2020-08-16 21:38:56 L66 StateSink snapshotState begin
2020-08-16 21:38:56 L55 StateSource send:55
2020-08-16 21:39:06 L66 StateSink snapshotState end
2020-08-16 21:39:06 L66 StateSource snapshotState begin
2020-08-16 21:39:16 L66 StateSource snapshotState end
2020-08-16 21:39:16 L55 StateSink recv:55
2020-08-16 21:39:16 L66 StateSink notifyCheckpointComplete 1
2020-08-16 21:39:16 L66 StateSource notifyCheckpointComplete 1
```

æ ¹æ®è¾“å‡ºå¯ä»¥ç®€å•æ¨æ–­å‡ºï¼š  
1. source/sink å¤„ç†æ•°æ®æ˜¯åœ¨åŒä¸€ä¸ªçº¿ç¨‹ï¼Œå› ä¸º chain ä¸ºäº†ä¸€ä¸ª JobVertexï¼Œç¬¦åˆé¢„æœŸ   
2. source/sink snapshotState æ˜¯åœ¨åŒä¸€ä¸ªçº¿ç¨‹ï¼Œä¸²è¡Œè¿›è¡Œï¼Œä¸€æ¬¡ checkpoit éœ€è¦ 20sï¼›ä¸”è·Ÿå¤„ç†æ•°æ®ä¸åŒçº¿ç¨‹  
3. è™½ç„¶ 1 2 çº¿ç¨‹ä¸åŒï¼Œä¸è¿‡ä»æ•ˆæœä¸Šçœ‹ä¸¤è€…æ˜¯äº’ç›¸é˜»å¡çš„å…³ç³»  
4. 21:38:56 StateSource å‘é€äº†æ•°æ®`55`ï¼Œ21:39:16 StateSink æ”¶åˆ°äº†è¯¥æ•°æ®ï¼Œå¾ˆæ˜æ˜¾ StateSink åœ¨ç¬¬ä¸€æ¬¡`snapshotState`æ—¶è¿˜æ²¡æœ‰æ”¶åˆ°è¿™æ¡æ•°æ®ï¼Œé‚£ StateSource ç¬¬ä¸€æ¬¡`snapshotState`æ—¶å¦‚ä½•ç¡®ä¿ä¸ä¼šåŒ…å«è¯¥æ•°æ®ï¼ˆç±»æ¯” KafkaSource çš„è¯ï¼Œå°±æ˜¯ä¸èƒ½å°† 55 è¿™ç§ on fly çš„æ•°æ®å¯¹åº”çš„ offset ä¸Šä¼ ï¼Œå› ä¸ºä¸‹æ¸¸ StateSink è¿˜æ²¡æœ‰ç¡®ä¿æ”¶åˆ°å¹¶ä¸”æŒä¹…åŒ–ï¼‰ 

ç»§ç»­ä¿®æ”¹ä¸‹ä»£ç  Source -> Sink ä¸º Source -> keyBy -> Sinkï¼Œè¿™æ ·ä¸¤è€…ä¸ä¼š chain ä¸ºä¸€ä¸ª JobVertex

```scala
  env.addSource(new StateSource)
    .keyBy(i => i)
    .addSink(new StateSink)
    .setParallelism(1)
```

è¿è¡Œçœ‹ä¸‹æ•ˆæœï¼š

```
2020-08-16 22:07:00 L53 StateSource initializeState
2020-08-16 22:07:00 L57 StateSource send:1
2020-08-16 22:07:00 L55 StateSink initializeState
2020-08-16 22:07:00 L55 StateSink recv:1
2020-08-16 22:07:01 L57 StateSource send:2
2020-08-16 22:07:01 L55 StateSink recv:2
2020-08-16 22:07:02 L57 StateSource send:3
2020-08-16 22:07:02 L55 StateSink recv:3
...
2020-08-16 22:07:51 L55 StateSink snapshotState begin
2020-08-16 22:07:51 L68 StateSource snapshotState begin
2020-08-16 22:07:52 L57 StateSource send:52
2020-08-16 22:08:01 L55 StateSink snapshotState end
2020-08-16 22:08:01 L68 StateSource snapshotState end
2020-08-16 22:08:01 L68 StateSource notifyCheckpointComplete 1
2020-08-16 22:08:01 L73 StateSink notifyCheckpointComplete 1
2020-08-16 22:08:01 L55 StateSink recv:52
```

å†åˆ†æä¸‹è¿™é‡Œçš„è¾“å‡ºï¼š 
1. source çš„å¤„ç†å’Œ snapshotState ä»ç„¶ä¸æ˜¯ä¸€ä¸ªçº¿ç¨‹
2. sink çš„å¤„ç†å’Œ snapshotState ç›¸åŒçº¿ç¨‹
3. source/sink çš„ snapshotState ç”±äºæ˜¯ä¸åŒçº¿ç¨‹ï¼Œå› æ­¤æ˜¯å¹¶è¡Œæ‰§è¡Œçš„ï¼Œä¸€æ¬¡ checkpoint éœ€è¦ 10s  
4. åŒæ ·éœ€è¦è€ƒè™‘ on fly çš„æ•°æ®

## 4. æ€è€ƒ

ä¸Šä¸€èŠ‚è§‚å¯Ÿåˆ°çš„ç¬¬äºŒç§æƒ…å†µï¼Œå¯¹åº”çš„æ˜¯è¿™ä¹ˆä¸€ä¸ªçº¿ç¨‹è°ƒç”¨æ¨¡å‹

![Checkpoint-Thread](/assets/images/flink-source-code/checkpoint-thread.png)

*æ³¨ï¼šå…·ä½“çº¿ç¨‹è°ƒç”¨è¿‡ç¨‹çš„ä»£ç è§£æï¼Œæˆ‘ä»¬æ”¾åˆ°ä¸‹ä¸€ç¯‡ç¬”è®°å•ç‹¬åˆ†æ*

1. sourceèŠ‚ç‚¹: ç”¨æˆ·å®ç°`SourceFunction.run`æµå¼çš„äº§å‡ºæ•°æ®ï¼Œå½“éœ€è¦è§¦å‘ checkpoint æ—¶ï¼Œä¼šç”±å…¶ä»–çº¿ç¨‹æ·»åŠ ä¸€ä¸ªæ ‡è®°æ•°æ®å‘é€åˆ°ä¸‹æ¸¸  
2. sinkèŠ‚ç‚¹: æ¥æ”¶æ•°æ®æ—¶ï¼Œå¦‚æœæ˜¯æ™®é€šæ•°æ®ï¼Œåˆ™è°ƒç”¨`SinkFunction.invoke`å¤„ç†ï¼Œå¦‚æœæ˜¯æ ‡è®°æ•°æ®ï¼Œåˆ™è°ƒç”¨`SinkFunction.snapshotState`å¤„ç†ï¼Œè¿™ä¹Ÿå°±è§£é‡Šäº†ä¸ºä»€ä¹ˆ`invoke/snapshotState`çº¿ç¨‹å·ç›¸åŒã€‚

`SinkFunction.snapshotState`å®Œæˆåï¼Œå°±æ„å‘³ç€æ‰¿è¯ºäº†æ•°æ® 1 2 3 å·²ç»å¤„ç†ï¼Œå¦‚æœæˆ‘ä»¬å¸Œæœ›å®ç°æ•°æ®æµçš„ At-Least Onceï¼Œé‚£ä¹ˆå¯¹äº source èŠ‚ç‚¹æ¥è®²ï¼Œéœ€è¦å°† lastOffset = 3(æ­¤æ¬¡ checkpoint çš„ä¸Šä¸€ä¸ª`i`çš„å€¼)è®°å½•ä¸‹æ¥ã€‚

1. ç”Ÿæˆæ•°æ®æ˜¯åœ¨`SourceFunction.run`ï¼Œè¿™é‡Œå¯ä»¥è®°å½•`i`  
2. è¯»å–`i`æ˜¯åœ¨`SourceFunction.snapshotState`ï¼ŒåŒæ—¶éœ€è¦ç¡®ä¿æ°å¥½æ˜¯å‘å‡º checkpoint barrier ä¹‹å‰çš„å€¼  

å‰é¢ä¸¤ç§æƒ…å†µçœ‹åˆ°ï¼Œ1 2ä½äºä¸åŒçº¿ç¨‹ï¼š

**å› æ­¤é—®é¢˜å˜æˆå¯¹ source èŠ‚ç‚¹ï¼Œè¿™ä¸¤ä¸ªçº¿ç¨‹ä¹‹é—´å¦‚ä½•å‡†ç¡®çš„åŒæ­¥ offset æ•°æ®ï¼Ÿ**

å…·ä½“æ¥è®²ï¼Œæ•°æ®æºäº§å‡ºæ•°æ®æ—¶éœ€è¦æš´éœ² offset å€¼ï¼Œä¾‹å¦‚ï¼š

```scala
override def run(ctx: SourceFunction.SourceContext[String]): Unit = {
  ...
  ctx.collect(i.toString)
  lastOffset = i
  ...
}
```

è€Œå¯¹æ·»åŠ æ ‡è®°æ•°æ®çš„çº¿ç¨‹è€Œè¨€ï¼š

```scala
sendCheckpointBarrier(...)
override def SourceFunction.snapshotState(...) = {
  ...
  currentOffset = lastOffset
  ...
}
```

è¿™ä¸¤ä¸ªæ“ä½œä¹‹é—´ï¼Œ`lastOffset`çš„å€¼ä¸èƒ½å‘ç”Ÿå˜åŒ–ï¼Œéœ€è¦ç¡®ä¿è·Ÿä¸‹æ¸¸çœ‹åˆ°çš„ä¹Ÿæ˜¯ä¸€è‡´çš„ã€‚

flink çš„å¤„ç†æ–¹å¼ä¹Ÿæ¯”è¾ƒç®€å•ç²—æš´ï¼Œå°±æ˜¯å¼ºåˆ¶çš„åŠ äº†ä¸€ä¸ªé”ç¡®ä¿ä¸¤è€…æ˜¯åŒæ­¥çš„ï¼Œå› æ­¤æˆ‘ä»¬åœ¨å®ç°`SourceFunction`æ—¶ï¼Œä¹Ÿéœ€è¦è€ƒè™‘ä½•æ—¶åŠ é”çš„é—®é¢˜ã€‚

å½“ SourceVertex SinkVertex çš„ snapshotState å·²ç»å®Œæˆï¼Œå°±ä¼šè°ƒç”¨`CheckpointListener.notifyCheckpointComplete`æ–¹æ³•é€šçŸ¥æ„Ÿå…´è¶£çš„ç®—å­ï¼Œä¾‹å¦‚åœ¨ SourceVertexï¼Œæˆ‘ä»¬å¯ä»¥è¿™ä¹ˆåšï¼š

```scala
override def notifyCheckpointComplete(checkpointId: Long): Unit = {
  persist((checkpoindId, currentOffset)      
}
```

è¿™æ ·å³ä½¿æ•°æ®æµé‡å¯ï¼Œæˆ‘ä»¬ä»æŒä¹…åŒ–çš„`(checkpointId, currentOffset)`æ¢å¤ï¼Œä¹Ÿå°±è‡ªç„¶è§£å†³ At-Least Once çš„éœ€æ±‚äº†ã€‚

è¿™ä¸ªä¸ç¬¦åˆæˆ‘æœ€å¼€å§‹çš„ç†è§£ï¼Œé¢„æœŸç”¨æˆ·ä¸åº”è¯¥å…³æ³¨åˆ°è¿™å±‚å®ç°ã€‚ä¸è¿‡ç»§ç»­è€ƒè™‘ä¸‹ï¼Œè¿™æˆ–è®¸æ˜¯æœ€ç›´æ¥æœ€æœ´ç´ çš„ä¸€ç§åšæ³•ã€‚

## 5. å®ç°

è¿™ä¸€èŠ‚æ ¹æ®å‰é¢çš„åˆ†æçœ‹ä¸‹æºç å®ç°ï¼Œåˆ†åˆ«æ˜¯ Kafka è®°å½•ä»¥åŠä¸Šä¼  offsetsï¼Œä»¥åŠ HBase çš„æŒä¹…åŒ–ã€‚

### 5.1. Kafka

`FlinkKafkaConsumerBase`ç»§æ‰¿è‡ª`RichParallelSourceFunction`ï¼Œåœ¨å…¶`run`çš„å®ç°é‡Œï¼Œä» topic æ¶ˆè´¹æ•°æ®ï¼Œç„¶åé€šè¿‡`SourceContext.collect`äº§å‡ºï¼Œç±»ä¼¼äº`StateSource`.

å¾ªç¯å§”æ‰˜ç»™äº†`AbstractFetcher`ï¼Œçœ‹ä¸‹äº§å‡ºæ•°æ®æ—¶çš„ä»£ç ï¼š

```java
public abstract class AbstractFetcher<T, KPH> {
  ...
  protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {

    if (record != null) {
      if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {
        // fast path logic, in case there are no watermarks

        // emit the record, using the checkpoint lock to guarantee
        // atomicity of record emission and offset state update
        synchronized (checkpointLock) {
          sourceContext.collect(record);
          partitionState.setOffset(offset);
        }
      } ...
  }
```

å¯ä»¥çœ‹åˆ°åŠ äº†ä¸€æŠŠé”`checkpointLock`ï¼Œä½¿å¾— å‘é€æ•°æ®å’Œè®¾ç½® offset æ˜¯åŸå­çš„ã€‚

å†çœ‹ä¸‹ snapshotState çš„å®ç°ï¼š

```java
public abstract class FlinkKafkaConsumerBase<T> extends RichParallelSourceFunction<T> implements
  ...
  public final void snapshotState(FunctionSnapshotContext context) throws Exception {
    ...
        HashMap<KafkaTopicPartition, Long> currentOffsets = fetcher.snapshotCurrentState();

        if (offsetCommitMode == OffsetCommitMode.ON_CHECKPOINTS) {
          // the map cannot be asynchronously updated, because only one checkpoint call can happen
          // on this function at a time: either snapshotState() or notifyCheckpointComplete()
          pendingOffsetsToCommit.put(context.getCheckpointId(), currentOffsets);
        }
```

å°†`currentOffsets`è®°å½•åˆ°äº†`pendingOffsetsToCommit`ï¼Œè¿™æ˜¯ä¸€ä¸ª`checkpointId -> offsets`çš„ HashMap ç»“æ„ï¼Œ`currentOffsets`é€šè¿‡`AbstractFetcher.snapshotCurrentState`è·å–

```java
  public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {
    // this method assumes that the checkpoint lock is held
    assert Thread.holdsLock(checkpointLock);

    HashMap<KafkaTopicPartition, Long> state = new HashMap<>(subscribedPartitionStates.size());
    for (KafkaTopicPartitionState<KPH> partition : subscribedPartitionStates) {
      state.put(partition.getKafkaTopicPartition(), partition.getOffset());
    }
    return state;
  }
```

`subscribedPartitionStates`å³`emitRecord`é‡Œçš„`partitionState`ï¼ŒåŒæ—¶æ³¨æ„æ³¨é‡Šå‡å®šå·²ç»æŒæœ‰äº†`checkpointLock`ï¼Œè¿™æ ·å°±ä¿è¯äº†è¿™é‡Œè¯»å–åˆ°çš„ offsets å¯¹åº”çš„æ•°æ®å·²ç»å‘é€å‡ºå»ã€‚

å½“æ‰€æœ‰ç®—å­çš„`snapshotState`å®Œæˆï¼Œflink è°ƒç”¨ç®—å­çš„`notifyCheckpointComplete`

```
  public final void notifyCheckpointComplete(long checkpointId) throws Exception {
    ...
      try {
        final int posInMap = pendingOffsetsToCommit.indexOf(checkpointId);
        ...
        Map<KafkaTopicPartition, Long> offsets =
          (Map<KafkaTopicPartition, Long>) pendingOffsetsToCommit.remove(posInMap);
        ...
        // ä¸Šä¼  offsets åˆ° kafka çš„ __consumer_offsets
        fetcher.commitInternalOffsetsToKafka(offsets, offsetCommitCallback);
```

å¯ä»¥çœ‹åˆ°æ­¤æ—¶å°†å¯¹åº” checkpoint çš„ offsets æ›´æ–°åˆ° kafka å°±å¯ä»¥äº†ã€‚

ä¸€å›¾èƒœåƒè¨€ï¼š

![kafka-subscribedPartitionStates](/assets/images/flink-source-code/kafka-subscribedPartitionStates.png)

### 5.2. HBase

HBase çš„å®ç°æ¯” Kafka ç®€å•å¾ˆå¤šï¼Œåªéœ€è¦å…³æ³¨`snapshotState`å°±å¯ä»¥äº†ï¼Œè€Œå®ç°è¯¥å‡½æ•°æ—¶ï¼Œä¸éœ€è¦ç”¨æˆ·ç¡®ä¿è·Ÿ`invoke`çš„åŒæ­¥å…³ç³»ã€‚

å¦‚æœè·Ÿ source ç›¸åŒ vertexï¼Œflink é€šè¿‡ checkpointLock åŒæ­¥ï¼Œå¦‚æœä¸åŒï¼Œåˆ™è·Ÿ`invoke`å¤©ç„¶åœ¨ä¸€ä¸ªçº¿ç¨‹ã€‚

```java
public class HBaseUpsertSinkFunction
    extends RichSinkFunction<Tuple2<Boolean, Row>>
    implements CheckpointedFunction, BufferedMutator.ExceptionListener {
    ...
  // æ¥æ”¶æ•°æ®ï¼Œå…ˆç¼“å­˜ï¼Œè¶…è¿‡ä¸€å®šæ•°é‡æ‰¹é‡ flush
  public void invoke(Tuple2<Boolean, Row> value, Context context) throws Exception {
    checkErrorAndRethrow();

    if (value.f0) {
      Put put = helper.createPutMutation(value.f1);
      mutator.mutate(put);
    } else {
      Delete delete = helper.createDeleteMutation(value.f1);
      mutator.mutate(delete);
    }

    // flush when the buffer number of mutations greater than the configured max size.
    if (bufferFlushMaxMutations > 0 && numPendingRequests.incrementAndGet() >= bufferFlushMaxMutations) {
      flush();
    }
  }

  // æ”¶åˆ° checkpoint barrierï¼Œåˆ™ flush ç¡®ä¿æ•°æ®å†™å…¥
  public void snapshotState(FunctionSnapshotContext context) throws Exception {
    while (numPendingRequests.get() != 0) {
      flush();
    }
  }
```

## 6. æ€è€ƒAgain

å¯ä»¥çœ‹åˆ°å¯¹äºé source ç®—å­ï¼Œå®ç°èµ·æ¥è¿˜æ˜¯æ¯”è¾ƒç®€å•çš„ã€‚å¯¹äºä¸€äº›éå¸¸ç®€å•çš„æ•°æ®æµï¼Œå…¶å®å®Œå…¨å’Œ barrier æ²¡æœ‰äº§ç”Ÿä»»ä½•å…³ç³»ï¼Œæ›´å¤šçš„æ˜¯é ä¸€ä¸ªè¶…å¤§èŒƒå›´çš„é”æ¥æä¾›æ•°æ®ä¸ä¸¢çš„åº•å±‚æ¶æ„ã€‚

ä½†æ˜¯å¯¹äº source ç®—å­ï¼Œflink æš´éœ²å‡ºçš„æ¥å£å°±æ²¡æœ‰è¿™ä¹ˆä¼˜é›…äº†ã€‚æˆ–è®¸å¯ä»¥å°†é”å°è£…åˆ°`SourceContext.collect`å†…éƒ¨é¿å…ç”¨æˆ·éœ€è¦è‡ªè¡ŒåŠ é”ï¼Œæˆ–è€…æˆ‘ç†è§£æ— è®ºæ˜¯æ™®é€šæ•°æ®ï¼Œè¿˜æ˜¯ CheckpointBarrierï¼Œæœ€ç»ˆéƒ½æ˜¯æ”¾åˆ°å‘é€çš„ FIFO é˜Ÿåˆ—ï¼Œèƒ½å¦æ”¯æŒå†™å…¥ä¸€äº›é¢å¤–çš„æ•°æ®ä¾‹å¦‚`offsets` `logid`ç­‰ï¼Œè¿™æ · flink å°±å¯ä»¥è‡ªè¡Œå®Œæˆ`SourceFunction.snapshotState`çš„è¡Œä¸ºï¼Œåœ¨`notifyCheckpointComplete`æ—¶å†è¿”å›ç»™ç”¨æˆ·ã€‚å½“ç„¶ï¼Œflink éœ€è¦è€ƒè™‘çš„åœºæ™¯å¤ªå¤šï¼Œä¾‹å¦‚ exactly-once ç­‰ï¼ŒåŸºäºè¿™äº›å¤æ‚åœºæ™¯å¤§æ¦‚æœ€ç»ˆæŠ˜è¡·æ˜¯è¿™æ ·ä¸€ä¸ªå®ç°ï¼Œæˆ‘ä»¬çš„æ€è€ƒæ›´å¤šæ˜¯çº¸ä¸Šè°ˆå…µäº†ã€‚

ä»é€»è¾‘ä¸Šçœ‹ï¼Œéœ€è¦é”ä½çš„èŒƒå›´åº”è¯¥åªæ˜¯è®°å½•å¯¹åº”çš„ offsetï¼Œè¿™ä¸ªé”çš„èŒƒå›´åº”è¯¥å°½å¯èƒ½çš„å°ï¼Œé‚£ä¹ˆå…¶åº•å±‚æ˜¯æ€æ ·ä¸€ä¸ªè¿‡ç¨‹ï¼Ÿç»†å¿ƒçš„è¯»è€…å¯èƒ½ä¹Ÿä¼šå‘ç°ï¼Œè¿™ç¯‡ç¬”è®°é‡Œè¿˜æ²¡æœ‰ä»‹ç»æ¸…æ¥šä¸€ä¸ªé—®é¢˜ï¼Œå¦‚æœè¦ç¡®ä¿æ•°æ®ä¸ä¸¢ï¼Œé‚£ä¹ˆ source å‘é€ barrier å‰çš„æ•°æ®éœ€è¦æ°å¥½æ˜¯ snapshotState è®°å½•çš„ offsetã€‚state å’Œ checkpoint çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿæ˜¯ä½•æ—¶è½ç›˜çš„ï¼Ÿ
