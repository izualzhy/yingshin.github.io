---
title: "ç‚’å†·é¥­ä¹‹ LLM è®ºæ–‡: CoTã€REACT"
date: 2025-07-05 01:42:17
tags: read ai
---

æ€»ç»“æˆ‘å¯¹å‡ ç¯‡ LLM è®ºæ–‡çš„ç†è§£ï¼Œè®ºæ–‡æ¥æºæ˜¯åœ¨åœ¨è¯»ã€Šå¤§æ¨¡å‹åº”ç”¨å¼€å‘ åŠ¨æ‰‹åšAI Agentã€‹æ—¶ï¼Œä¹¦é‡Œæ¨èçš„å‡ ç¯‡ã€‚  
è¿™ç¯‡æ–‡ç« ä¸»è¦æ˜¯ COT å’Œ REACT , è®ºæ–‡å¤§å¤šæŠ½è±¡ï¼Œæ–‡ç« é‡Œå°½é‡ç”¨ä»£ç å®é™…éªŒè¯æ¥è¯´æ˜æˆ‘çš„ä¸ªäººç†è§£ã€‚

# 1. [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)

æ³¨æ„è®ºæ–‡æ˜¯åœ¨ 2022å¹´1æœˆ å‘è¡¨çš„ï¼Œä¹‹æ‰€ä»¥ç¬”è®°æ ‡é¢˜å«åšç‚’å†·é¥­ï¼ŒåŸå› ä¹Ÿåœ¨äºæ­¤ã€‚è™½ç„¶åªéš”äº†ä¸‰å¹´æ—¶é—´ï¼Œä½†æ˜¯å¤§æ¨¡å‹çš„å‘å±•è¿…é€Ÿï¼Œæœ‰äº›ä¾‹å­å·²ç»ä¸é€‚ç”¨ã€‚ä¹‹å‰è¯´â€œä¸€æ—¥ä¸è§å¦‚éš”ä¸‰ç§‹â€ï¼Œæ”¾åœ¨ AI é¢†åŸŸçœŸæ˜¯å¤ªåˆé€‚ä¸è¿‡ï¼Œä¸‰å¹´å·²è¿‡ï¼Œå¦‚åŒä¸Šä¸ªä¸–çºªã€‚

æ–‡ç« é‡Œçš„è¿™ä¸ªå›¾ç°åœ¨å¼•ç”¨å·²ç»éå¸¸å¹¿æ³›äº†ï¼š

![cot_figure_1](/assets/images/ai-paper/cot_figure_1.png)

æˆ‘ä½¿ç”¨ä»£ç å®é™…æµ‹è¯•äº†ä¸‹ï¼š

```python
def testCOT(llm: ChatOpenAI):
    question = """Q: Roger has 5 tennis balls. He buys 2 more cans of
tennis balls. Each can has 3 tennis balls. How many
tennis balls does he have now?
A: The answer is 11.
Q: The cafeteria had 23 apples. If they used 20 to
make lunch and bought 6 more, how many apples
do they have?"""
    print('-'*32 + ' not cot ' + '-'*32)
    print(invokeLLM(llm, question))

    question = """"Q: Roger has 5 tennis balls. He buys 2 more cans of
tennis balls. Each can has 3 tennis balls. How many
tennis balls does he have now?
A: Roger started with 5 balls. 2 cans of 3 tennis balls
each is 6 tennis balls. 5 + 6 = 11. The answer is 11.
Q: The cafeteria had 23 apples. If they used 20 to
make lunch and bought 6 more, how many apples
do they have?"""
    print('-'*32 + ' cot ' + '-'*32)
    print(invokeLLM(llm, question))
```

è¿™æ˜¯ç”¨ doubaoseed1.6 æŸæ¬¡è¾“å‡ºçš„æ•ˆæœï¼š

```
-------------------------------- not cot --------------------------------
The cafeteria starts with 23 apples. They use 20, so subtract 20: 23 - 20 = 3. Then they buy 6 more, so add 6: 3 + 6 = 9. The answer is 9.
-------------------------------- cot --------------------------------
A: The cafeteria started with 23 apples. They used 20 apples, so 23 - 20 = 3 apples left. Then they bought 6 more, so 3 + 6 = 9. The answer is 9.
```

doubao1.5visionlite æŸæ¬¡è¾“å‡ºçš„æ•ˆæœï¼š

```
-------------------------------- not cot --------------------------------
First, find out how many apples are left after using some:
The cafeteria had 23 apples and used 20, so the number of apples left is \(23 - 20= 3\).
Then, they bought 6 more apples. So the total number of apples now is \(3 + 6 = 9\).
The answer is 9.
-------------------------------- cot --------------------------------
The cafeteria started with 23 apples. They used 20 apples, so they had 23 - 20 = 3 apples left. Then they bought 6 more apples. 3 + 6 = 9. The answer is 9.
```

ç”¨ deepseek-r1 æŸæ¬¡è¾“å‡ºçš„æ•ˆæœï¼š
```
-------------------------------- not cot --------------------------------

The cafeteria started with 23 apples.  
They used 20 apples to make lunch, which means they have 23 - 20 = 3 apples left.  
Then, they bought 6 more apples, so they have 3 + 6 = 9 apples now.  

Alternatively, the net change is -20 (used) + 6 (bought) = -14, so 23 + (-14) = 9.  
Regardless of the order of operations, the result is consistent: 23 - 20 + 6 = 9, or 23 + 6 - 20 = 9.  

Thus, the cafeteria now has 9 apples.

\boxed{9}
-------------------------------- cot --------------------------------

The cafeteria started with 23 apples.  
They used 20 apples for lunch, so they had 23 - 20 = 3 apples left.  
Then they bought 6 more apples, so 3 + 6 = 9.  
The answer is 9.
```

å¯ä»¥çœ‹åˆ°ç”¨ç°åœ¨çš„å¤§æ¨¡å‹ï¼Œå›ç­”å…¶å®éƒ½æ˜¯å‡†ç¡®çš„ã€‚
{:.warning}

æˆ‘å°è¯•å¤šæ¬¡è°ƒç”¨ï¼Œä»¥åŠè¾“å…¥å…¶ä»–é—®é¢˜ï¼Œä¾‹å¦‚ï¼š
1. Maryâ€™s father has five daughters: Nana, Nene, Nini, Nono. What is the name of the fifth daughter?(ä¸ºäº†å¼•å¯¼æ¨¡å‹é€æ­¥æ¨ç†ï¼ŒåŠ å…¥è¿™ä¸€å¥"Let's think step by step.")
2. Mike plays ping pong for 40 minutes. In the first 20 minutes, he scores 4 points. In the second 20 minutes, he scores 25% more points. How many total points did he score?

å³ä½¿ä½¿ç”¨ Standard Prompting è€Œä¸æ˜¯ Chain-of-Thought Prompting ï¼Œæ¨¡å‹åœ¨è¾“å‡ºæ—¶ä¸ä»…å±•ç°äº†æ¨ç†èƒ½åŠ›ï¼Œè€Œä¸”ä¹Ÿèƒ½å¤Ÿè¾“å‡ºæ­£ç¡®ç­”æ¡ˆã€‚

æ¯æ¬¡è°ƒç”¨ç»“æœä¸åŒï¼Œå¦‚æœåœ¨ Prompt é‡Œå°è¯•å¼•å¯¼æ¨¡å‹æ¨ç†ï¼Œç¬¦åˆé¢„æœŸçš„æ¦‚ç‡ç¡®å®æ›´å¤§ä¸€äº›ã€‚

<p class="success">
    æˆ‘çš„ç†è§£æ˜¯å¤§æ¨¡å‹çš„æ•ˆæœå°±åƒæ˜¯ä¸€ä¸ª V å­—å‹ï¼Œå·¦è¾¹æ˜¯è®­ç»ƒç”Ÿæˆæ¨¡å‹ï¼Œå³è¾¹æ˜¯æŸ¥è¯¢æ¨¡å‹ï¼Œä¸¤è¾¹éƒ½ä¼šå½±å“æ¨ç†æ•ˆæœï¼š<br/>
1. ç°åœ¨çš„å¾ˆå¤šå¤§æ¨¡å‹ï¼Œåœ¨å·¦è¾¹å°±å·²ç»ä½¿ç”¨æ›´ç²¾ç¡®çš„æ•°æ®ã€è°ƒä¼˜è§£å†³äº†æˆ‘æµ‹è¯•çš„è¿™äº› queryï¼Œå› æ­¤å³ä½¿ä¸ä½¿ç”¨ COT ï¼Œæ•ˆæœä¹Ÿéå¸¸å¥½äº†ã€‚<br/>
2. ä¸ºäº†æ›´å¤§æ¦‚ç‡çš„æ‹¿åˆ°æƒ³è¦çš„è¾“å‡ºï¼Œè¿˜æ˜¯åº”å½“å°½é‡ä½¿ç”¨ COT<br/>
3. ç›¸æ¯”åç»­å‡ºç°çš„ç­–ç•¥ï¼ŒCOT æœ€ä¸ºåŸºç¡€å’Œç›´æ¥ã€‚å› ä¸º COT åªä½¿ç”¨äº† Prompt æ¥æå‡æ•ˆæœï¼Œå› æ­¤ä¹Ÿæ˜¯ Prompt Engine çš„ä¸€ç§ä½“ç°ã€‚(æ³¨ï¼šæˆ‘æŸ¥äº†ä¸‹ä¼¼ä¹æå‡º PE åªæ¯” COT æ—©äº†åŠå¹´)<br/>
4. COT çš„æœ¬è´¨æ˜¯è¦å¼•å¯¼å¤§æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ï¼Œç°åœ¨çœ‹å…¶å®å·²ç»æ˜¯æ¯”è¾ƒæ™®éçš„æ€æƒ³äº†ã€‚<br/>
</p>

ç°åœ¨æƒ³æƒ³ä¹Ÿæ˜¯åˆç†çš„ã€‚å°±åƒæˆ‘ä»¬è‡ªå·±è®¡ç®—é”™è¯¯åï¼Œä¼šè·Ÿè‡ªå·±è¯´â€œä½ å†ä»”ç»†æƒ³æƒ³â€ã€‚â€œå¤šæƒ³æƒ³ï¼ŒæŒ‰ç…§å·²çŸ¥æƒ…å†µæ¼”ç»/æ¨ç†å‡ éï¼Œå°±ä¼šå°‘çŠ¯é”™â€ï¼Œæ”¾åœ¨å¤§æ¨¡å‹è¿™é‡Œç”¨äº†ä¸€ä¸ªæ–°åè¯ï¼Œå³ COT.

*ç›¸å…³ä»£ç æ”¾åœ¨ <https://github.com/izualzhy/AI-Systems/blob/main/misc/read_paper_cot.py>*

# 2. [REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS](https://arxiv.org/abs/2210.03629)

![react_figure_1](/assets/images/ai-paper/react_figure_1.png)

åˆ°äº†è¿™ä¸ªé˜¶æ®µ(2022å¹´10æœˆ)ï¼Œå¼€å§‹åœ¨ COT çš„æ€æƒ³ä¸Šå¼•å…¥å·¥å…·ã€‚è¿™ç¯‡è®ºæ–‡ä¸»è¦æå‡ºäº†å¦‚ä½•ç»“åˆæ¨ç†å’Œå·¥å…·ï¼Œä»¥å¼•å¯¼å¤§æ¨¡å‹è¿”å›æ›´å¥½çš„ç»“æœã€‚

é‚£å­¦æœ¯ç•Œçš„è¿™ä¸ªè®ºæ–‡åº”è¯¥å¦‚ä½•åº”ç”¨ï¼Ÿ

ä¸»è¦æœ‰ä¸¤å¤„ï¼š

1. è®¾è®¡ Promptï¼Œä»¥åŠè§£æå¤§æ¨¡å‹è¿”å›çš„ç»“æœ  
2. å¾ªç¯ï¼šè°ƒç”¨å·¥å…·ã€æ ¹æ®å·¥å…·è¾“å‡ºç»§ç»­è°ƒç”¨å¤§æ¨¡å‹ï¼Œç›´åˆ°è¾¾åˆ°æ¬¡æ•°é˜ˆå€¼

æˆ‘ä»¬ç”¨ LangChain å®é™…æµ‹è¯•çœ‹çœ‹ï¼š
```python
def get_current_weather(location: str):
    print(f"\n** [å‡½æ•°è¢«è°ƒç”¨] location = {location} **\n")
    return f"{location} ä»Šå¤©å¤©æ°”æ™´ï¼Œ25Â°C."

tools = [
    Tool.from_function(
        func=get_current_weather,
        name="get_current_weather",
        description="è·å–åŸå¸‚å½“å‰å¤©æ°”",
        handle_parsing_errors=True
    )
]

# åˆå§‹åŒ– Agent
# llm = getDoubaoSeed16()
llm = getDoubao15VisionLite()
# llm = getDeepSeekR1()

def v1():
    # llm = getDeepSeekR1()
    agent = initialize_agent(tools,
                             llm,
                             agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
                             # agent_type="openai-tools",
                             verbose=True,
                             temperature=0,
                             handle_parsing_errors=True)

    def run():
        print(agent.agent.llm_chain.prompt.template)
        # ç”¨æˆ·æé—®
        result = agent.invoke("è¯·é—®ä¸Šæµ·çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")
        print(result)
    
    run()
```

ä¸Šè¿°ä»£ç è¾“å‡ºï¼š
```
Answer the following questions as best you can. You have access to the following tools:

get_current_weather(location: str) - è·å–åŸå¸‚å½“å‰å¤©æ°”

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [get_current_weather]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

Question: {input}
Thought:{agent_scratchpad}


> Entering new AgentExecutor chain...
Thought: éœ€è¦è·å–ä¸Šæµ·å½“å‰çš„å¤©æ°”ä¿¡æ¯ï¼Œè°ƒç”¨ get_current_weather å·¥å…·æ¥å®ç°
Action: get_current_weather
Action Input: ä¸Šæµ·
** [å‡½æ•°è¢«è°ƒç”¨] location = ä¸Šæµ· **


Observation: ä¸Šæµ· ä»Šå¤©å¤©æ°”æ™´ï¼Œ25Â°C.
Thought:I now know the final answer
Final Answer: ä¸Šæµ· ä»Šå¤©å¤©æ°”æ™´ï¼Œ25Â°C.

> Finished chain.
```

å¯ä»¥çœ‹åˆ°å‡½æ•°è¢«è°ƒç”¨ï¼Œä¸”è¿”å›äº†é¢„æœŸçš„æœ€ç»ˆç­”æ¡ˆã€‚

## 2.1. Prompt

`print(agent.agent.llm_chain.prompt.template)`å¯ä»¥è·å–å†…ç½®çš„ Promptï¼š

```
Answer the following questions as best you can. You have access to the following tools:

get_current_weather(location: str) - è·å–åŸå¸‚å½“å‰å¤©æ°”

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [get_current_weather]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

Question: {input}
Thought:{agent_scratchpad}
```

`Question -> Thought -> Action -> ActionInput -> Observation -> Thought -> ... -> Final Answer`å¼•å¯¼å¤§æ¨¡å‹æŒ‰ç…§è¿™ä¸ªè¿‡ç¨‹æ¨ç†å’Œè¾“å‡ºï¼Œä¹Ÿæ˜¯ REACT çš„æ ‡å‡†æ–¹å¼ã€‚

## 2.2. å¾ªç¯

```python
class AgentExecutor(Chain):

    def _call(
        self,
        inputs: dict[str, str],
        run_manager: Optional[CallbackManagerForChainRun] = None,
    ) -> dict[str, Any]:
        """Run text through and get agent response."""
        # Construct a mapping of tool name to tool for easy lookup
        name_to_tool_map = {tool.name: tool for tool in self.tools}
        # We construct a mapping from each tool to a color, used for logging.
        color_mapping = get_color_mapping(
            [tool.name for tool in self.tools], excluded_colors=["green", "red"]
        )
        intermediate_steps: list[tuple[AgentAction, str]] = []
        # Let's start tracking the number of iterations and time elapsed
        iterations = 0
        time_elapsed = 0.0
        start_time = time.time()
        # We now enter the agent loop (until it returns something).
        while self._should_continue(iterations, time_elapsed):
            next_step_output = self._take_next_step(
                name_to_tool_map,
                color_mapping,
                inputs,
                intermediate_steps,
                run_manager=run_manager,
            )
            if isinstance(next_step_output, AgentFinish):
                return self._return(
                    next_step_output, intermediate_steps, run_manager=run_manager
                )

            intermediate_steps.extend(next_step_output)
            if len(next_step_output) == 1:
                next_step_action = next_step_output[0]
                # See if tool should return directly
                tool_return = self._get_tool_return(next_step_action)
                if tool_return is not None:
                    return self._return(
                        tool_return, intermediate_steps, run_manager=run_manager
                    )
            iterations += 1
            time_elapsed = time.time() - start_time
        output = self._action_agent.return_stopped_response(
            self.early_stopping_method, intermediate_steps, **inputs
        )
        return self._return(output, intermediate_steps, run_manager=run_manager)
```

å¾ªç¯çš„è¿‡ç¨‹åœ¨ä¸Šè¿°ä»£ç é‡Œï¼Œéµå¾ª`è°ƒç”¨å¤§æ¨¡å‹ -> è§£æå¤§æ¨¡å‹è¿”å›ç»“æœ(action/final answer) -> æ‰§è¡Œ -> æ ¹æ®æ‰§è¡Œç»“æœç»§ç»­è°ƒç”¨...`.

`_should_continue`é‡Œä¼ å…¥äº†è¿­ä»£æ¬¡æ•°ã€æ¶ˆè€—æ—¶é—´ï¼Œé¿å…é™·å…¥å¾ªç¯ä¸€ç›´ä¸è¿”å›ã€‚

è§£æè¿”å›ç»“æœï¼š

```python
class MRKLOutputParser(AgentOutputParser):

    def parse(self, text: str) -> Union[AgentAction, AgentFinish]:
        """Parse the output from the agent into
        an AgentAction or AgentFinish object.

        Args:
            text: The text to parse.

        Returns:
            An AgentAction or AgentFinish object.

        Raises:
            OutputParserException: If the output could not be parsed.
        """
        includes_answer = FINAL_ANSWER_ACTION in text
        regex = (
            r"Action\s*\d*\s*:[\s]*(.*?)[\s]*Action\s*\d*\s*Input\s*\d*\s*:[\s]*(.*)"
        )
        action_match = re.search(regex, text, re.DOTALL)
        if action_match and includes_answer:
            ...
```

æ‰§è¡Œå·¥å…·çš„è°ƒç”¨æ ˆï¼š
```
AgentExecutor._take_next_step -> 
AgentExecutor._iter_next_step ->
AgentExecutor._perform_agent_action ->
BaseTool.run ->
Tool._run ->
è‡ªå®šä¹‰å‡½æ•°
```

ç”±äºå¤§æ¨¡å‹çš„æ¡†æ¶éƒ½åœ¨å¿«é€Ÿè¿­ä»£(æ¢å¥è¯è¯´ä¸æˆç†ŸğŸ˜„)ï¼Œå°±ä¸æ·±å…¥å¼€å±•äº†ã€‚è¿™ç¯‡ç¬”è®°çš„ç›®çš„ä¹Ÿæ˜¯ä¸»è¦ç”¨æ¥ç†è§£ REACT çš„è¿‡ç¨‹ã€‚

## 2.3. æˆ‘ä¸ç†è§£çš„

å®é™…ä¸Šä¸Šè¿°ä»£ç ï¼Œæˆ‘ç¬¬ä¸€æ¬¡èŠ±äº†å‡ ä¸ªå°æ—¶éƒ½æ²¡æœ‰è·‘é€šï¼ˆä¸å¾—ä¸åæ§½æœåˆ°çš„å¾ˆå¤šæ–‡ç« ï¼ŒåŒ…æ‹¬ä¸€äº›è¯¾ç¨‹æ–‡ç« ï¼ŒåŸºæœ¬éƒ½æ˜¯å¤è¯»æœºä¸€æ ·æŒ‘ç€ REACT çš„æ¦‚å¿µåœ¨è®²ï¼‰ã€‚

ç›´åˆ°æˆ‘ä» Doubao-Seed-1.6 DeepSeek-R1 æ¢æˆäº† Doubao-1.5-vision-lite æ¨¡å‹ã€‚ä½¿ç”¨å‰ä¸¤è€…çš„è¯ï¼Œè¿”å›ç»“æœä¸Šé—®é¢˜å¾ˆå¤šï¼Œæ¯”å¦‚ï¼š

1. æ—¢è¾“å‡ºäº† Final Answerï¼Œåˆè¾“å‡ºäº† Actionï¼ŒLangChain ä¸çŸ¥é“æ˜¯å¦åº”è¯¥ç»“æŸå¾ªç¯  
2. æ²¡æœ‰è°ƒç”¨æˆ‘å®šä¹‰çš„ toolï¼Œåè€Œè¾“å‡ºäº†ä¸€å †è‡ªè®¤ä¸ºçš„å…³äºä¸Šæµ·å¤©æ°”çš„è¯­å¥ï¼ˆè®­ç»ƒä¸­åŠ å…¥çš„ï¼Ÿï¼‰

éšç€æ¨¡å‹å˜é«˜çº§ï¼Œè¿”å›ç»“æœåè€Œä¸éµå®ˆ Prompt äº†ï¼Ÿ

<p class="success">
    æˆ‘çš„ç†è§£æ˜¯
1. å¤§æ¨¡å‹é æ¦‚ç‡è¾“å‡ºä¸‹ä¸€ä¸ªå­—ç¬¦ï¼Œæœ¬è´¨ä¸Šä¸èƒ½ä¿è¯ç­”æ¡ˆ100%å‡†ç¡®ã€‚è€Œäººä»¬å´å¸Œæœ›è·å–100%å‡†ç¡®çš„ç­”æ¡ˆï¼Œæ€ä¹ˆè§£å†³ï¼Ÿç­”æ¡ˆå°±æ˜¯å¼•å…¥å·¥å…·ã€‚æ€ä¹ˆè®©æ¨¡å‹è°ƒç”¨å·¥å…·ï¼Ÿç­”æ¡ˆå°±æ˜¯ REACT.<br/>
2. æ ¹æ®æˆ‘ä¸ç†è§£çš„é‚£äº›å†…å®¹ï¼Œå¯ä»¥çœ‹åˆ°æ•ˆæœå¯¹ æ¨¡å‹+Prompt çš„ä¾èµ–è¿˜æ˜¯éå¸¸å¤§çš„ï¼Œæ¢ä¸ªæ¨¡å‹å°±å¯¼è‡´ç»“æœé”™ä¹±ã€‚<br/>
3. è¿™è®©æˆ‘æƒ³åˆ°æ¥è§¦ Agent ä¹‹åæœ€åˆçš„ç–‘é—®ï¼Œæˆ‘ä»¬ç°åœ¨é€šè¿‡ Prompt æ§åˆ¶å¤§æ¨¡å‹çš„è¿”å›ï¼Œåªæ˜¯é è§‚å¯Ÿåˆ°è¿™ç§ç°è±¡å¾—åˆ°çš„ç»“è®ºã€‚åƒæäº†å†œåœºé¸¡èˆçš„ç§‘å­¦å®¶ã€‚<br/>
4. REACT å¼•å…¥å·¥å…·çš„ç›®çš„ï¼Œæœ€å¼€å§‹æ˜¯ä¸ºäº†è·å–æ›´å‡†ç¡®çš„ç­”æ¡ˆã€‚è€Œæ¨åŠ¨å·¥å…·å‘å±•çš„åŒæ—¶ï¼Œæˆ‘ä»¬æƒ³è±¡åŠ›è¿›ä¸€æ­¥æ”¾å¤§ï¼Œå¼€å§‹å¸Œæœ›ç”¨ Agent å»åšæ›´å¤šäº‹æƒ…ã€‚<br/>
</p>
*æ³¨ï¼šç›¸å…³ä»£ç åœ¨ <https://github.com/izualzhy/AI-Systems/blob/main/misc/read_paper_react.py>*

